{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c7344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "#  SOKM_es_editor.py · v1.0 (single-shot, no CLI, no dictionary)\n",
    "#  — Post-edits Spanish translations given English source lines in ONE request\n",
    "#    - Preserves <br/> for subtitles (enforced by system prompt you provide)\n",
    "#    - Reads system prompt from external .txt file\n",
    "# =============================================================================\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ── LLM provider selection ---------------------------------------------------\n",
    "# Set MODEL_PROVIDER = \"openai\" or \"gemini\"\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "MODEL_NAME     = \"gpt-5\"          # e.g., \"gpt-5\" or \"gemini-2.5-pro\"\n",
    "\n",
    "load_dotenv()  # loads OPENAI_API_KEY or GOOGLE_API_KEY if present\n",
    "\n",
    "# Provider initialization (kept simple, no CLI)\n",
    "def _init_provider(provider: str, model_name: str):\n",
    "    p = provider.lower().strip()\n",
    "    if p == \"openai\":\n",
    "        import openai\n",
    "        client = openai.OpenAI()\n",
    "        return p, client, model_name\n",
    "    elif p == \"gemini\":\n",
    "        import google.generativeai as genai\n",
    "        genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "        return p, genai, model_name\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown provider: {provider!r}. Use 'openai' or 'gemini'.\")\n",
    "\n",
    "# ── Helpers ------------------------------------------------------------------\n",
    "def read_file(path: str) -> str:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    return p.read_text(encoding=\"utf-8\").strip()\n",
    "\n",
    "def read_csv(path: str) -> pd.DataFrame:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Input CSV not found: {path}\")\n",
    "    return pd.read_csv(p)\n",
    "\n",
    "def find_columns(df: pd.DataFrame) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Detect English and Spanish columns:\n",
    "      - English: 'Cleaned Text' (common in your file) or 'Segment Text'\n",
    "      - Spanish: 'Translated Text'\n",
    "    \"\"\"\n",
    "    candidates_en = [\"Cleaned Text\", \"Segment Text\"]\n",
    "    en_col = next((c for c in candidates_en if c in df.columns), None)\n",
    "    es_col = \"Translated Text\" if \"Translated Text\" in df.columns else None\n",
    "    if not en_col or not es_col:\n",
    "        raise ValueError(\n",
    "            \"CSV must include English + Spanish columns. \"\n",
    "            \"English: 'Cleaned Text' or 'Segment Text' | Spanish: 'Translated Text'\"\n",
    "        )\n",
    "    return en_col, es_col\n",
    "\n",
    "def build_pairs(df: pd.DataFrame, en_col: str, es_col: str) -> dict:\n",
    "    \"\"\"\n",
    "    Build {row_index_str: {\"en\": ..., \"es\": ...}} for all rows with strings on both sides.\n",
    "    \"\"\"\n",
    "    pairs = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        en = row.get(en_col, None)\n",
    "        es = row.get(es_col, None)\n",
    "        if isinstance(en, str) and isinstance(es, str):\n",
    "            pairs[str(idx)] = {\"en\": en, \"es\": es}\n",
    "    return pairs\n",
    "\n",
    "def build_user_prompt(pairs: dict, provider: str) -> str:\n",
    "    \"\"\"\n",
    "    User prompt; your system prompt (with <br/> preservation rules) is read from file.\n",
    "    \"\"\"\n",
    "    pairs_json = json.dumps(pairs, ensure_ascii=False, indent=2)\n",
    "    if provider == \"openai\":\n",
    "        return (\n",
    "            \"# Correction Task\\n\\n\"\n",
    "            \"You will receive a JSON object where each key maps to an object: \"\n",
    "            '{\"en\": \"...\", \"es\": \"...\"}. '\n",
    "            \"Return ONE JSON object with the SAME KEYS and the corrected Spanish string as each value. \"\n",
    "            \"Keep strings unchanged when already correct. Follow the system prompt rules.\\n\\n\"\n",
    "            \"## Input JSON\\n\" + pairs_json\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            \"Correct the Spanish lines in the JSON (same keys). Return JSON only.\\n\\n\"\n",
    "            \"Input JSON:\\n\" + pairs_json\n",
    "        )\n",
    "\n",
    "def call_llm_one_shot(provider: str, client, model_name: str, system_prompt: str, pairs: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Make a single LLM call with the entire transcript. Returns corrections dict.\n",
    "    \"\"\"\n",
    "    user_prompt = build_user_prompt(pairs, provider)\n",
    "    try:\n",
    "        if provider == \"openai\":\n",
    "            # Requires OPENAI_API_KEY in env\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                temperature=1,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\",   \"content\": user_prompt},\n",
    "                ],\n",
    "            )\n",
    "            return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "        else:  # gemini\n",
    "            # Requires GOOGLE_API_KEY in env\n",
    "            model = client.GenerativeModel(\n",
    "                model_name=model_name,\n",
    "                system_instruction=system_prompt,\n",
    "                generation_config={\n",
    "                    \"temperature\": 1,\n",
    "                    \"response_mime_type\": \"application/json\",\n",
    "                },\n",
    "            )\n",
    "            resp = model.generate_content(user_prompt)\n",
    "            return json.loads(resp.text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"⚠️  LLM call failed:\", e)\n",
    "        return {}\n",
    "\n",
    "def apply_corrections(df: pd.DataFrame, corrections: dict, output_col: str) -> pd.DataFrame:\n",
    "    df[output_col] = pd.NA\n",
    "    for k, v in corrections.items():\n",
    "        try:\n",
    "            i = int(k)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        df.loc[i, output_col] = v\n",
    "    return df\n",
    "\n",
    "# ── Main (everything configured here) ---------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # ‣‣‣ Adjust these paths --------------------------------------------------\n",
    "    input_csv_path     = r\"D:\\SOKM\\11 Identity 2 SoKM 2024 - 2025\\11 Identity 2 SoKM 2024 - 2025_transcript_english_SE_br_converted_cleaned_gpt_4_1_translated_d_openai_gpt_5_pv2.0.csv\"\n",
    "    system_prompt_file = \"system_prompt_editor_v1.0.txt\"   # your post-edit rules (preserve <br/>)\n",
    "    output_csv_path    = input_csv_path.replace(\".csv\", \"_edited.csv\")\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    provider, client, model_name = _init_provider(MODEL_PROVIDER, MODEL_NAME)\n",
    "\n",
    "    # Load resources\n",
    "    system_prompt = read_file(system_prompt_file)\n",
    "    df = read_csv(input_csv_path)\n",
    "    en_col, es_col = find_columns(df)\n",
    "\n",
    "    print(f\"Detected English column:  {en_col}\")\n",
    "    print(f\"Detected Spanish column:  {es_col}\")\n",
    "\n",
    "    # Build one-shot payload\n",
    "    pairs = build_pairs(df, en_col, es_col)\n",
    "    if not pairs:\n",
    "        raise RuntimeError(\"No valid EN–ES pairs found to process.\")\n",
    "\n",
    "    print(f\"Submitting {len(pairs)} lines in ONE request to {provider}:{model_name} …\")\n",
    "    print(\"Note: very large transcripts can hit model token limits.\")\n",
    "\n",
    "    # Single LLM call (no batching)\n",
    "    corrections = call_llm_one_shot(\n",
    "        provider=provider,\n",
    "        client=client,\n",
    "        model_name=model_name,\n",
    "        system_prompt=system_prompt,\n",
    "        pairs=pairs,\n",
    "    )\n",
    "    if not corrections:\n",
    "        raise RuntimeError(\"Empty corrections received from model.\")\n",
    "\n",
    "    # Apply corrections, keep originals where missing\n",
    "    corrected_col = \"Translated Text (edited)\"\n",
    "    df = apply_corrections(df, corrections, corrected_col)\n",
    "    mask_missing = df[corrected_col].isna()\n",
    "    if mask_missing.any():\n",
    "        df.loc[mask_missing, corrected_col] = df.loc[mask_missing, es_col]\n",
    "\n",
    "    # Save\n",
    "    Path(output_csv_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(output_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ Finished → {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e846ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify if the entries in the column are identical between two DataFrames\n",
    "#Any column with the same name needs to be verified\n",
    "def verify_identical_entries(df1: pd.DataFrame, df2: pd.DataFrame) -> dict:\n",
    "    common_columns = df1.columns.intersection(df2.columns)\n",
    "    results = {}\n",
    "    for col in common_columns:\n",
    "        results[col] = df1[col].equals(df2[col])\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df1 = pd.read_csv(r\"D:\\SOKM\\11 Identity 2 SoKM 2024 - 2025\\11 Identity 2 SoKM 2024 - 2025_transcript_english_SE_br_converted_cleaned_gpt_4_1_translated_d_openai_gpt_5_pv2.0.csv\")\n",
    "    df2 = pd.read_csv(r\"D:\\SOKM\\11 Identity 2 SoKM 2024 - 2025\\11 Identity 2 SoKM 2024 - 2025_transcript_english_SE_br_converted_cleaned_gpt_4_1_translated_d_openai_gpt_5_pv2.0_edited.csv\")\n",
    "    results = verify_identical_entries(df1, df2)\n",
    "    for col, is_identical in results.items():\n",
    "        status = \"identical\" if is_identical else \"different\"\n",
    "        print(f\"Column '{col}' is {status} between the two DataFrames.\")\n",
    "        if not is_identical:\n",
    "            differing_rows = df1[df1[col] != df2[col]]\n",
    "            print(f\"Differing rows in column '{col}':\")\n",
    "            print(differing_rows)\n",
    "    print(\"Verification complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0deb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify identical entries between two columns in the same csv\n",
    "def verify_identical_columns(df: pd.DataFrame, col1: str, col2: str) -> bool:\n",
    "    if col1 not in df.columns or col2 not in df.columns:\n",
    "        raise ValueError(f\"Columns '{col1}' and '{col2}' must be present in the DataFrame.\")\n",
    "    return df[col1].equals(df[col2])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(r\"D:\\SOKM\\11 Identity 2 SoKM 2024 - 2025\\11 Identity 2 SoKM 2024 - 2025_transcript_english_SE_br_converted_cleaned_gpt_4_1_translated_d_openai_gpt_5_pv2.0_edited.csv\")\n",
    "\n",
    "    col1 = \"Translated Text\"\n",
    "    col2 = \"Translated Text (edited)\"\n",
    "    are_identical = verify_identical_columns(df, col1, col2)\n",
    "    if are_identical:\n",
    "        print(f\"Columns '{col1}' and '{col2}' are identical.\")\n",
    "    else:\n",
    "        print(f\"Columns '{col1}' and '{col2}' are different.\")\n",
    "        differing_rows = df[df[col1] != df[col2]]\n",
    "        print(f\"Number of differing rows: {len(differing_rows)}\")\n",
    "        print(f\"Differing rows between columns '{col1}' and '{col2}':\")\n",
    "        print(differing_rows)\n",
    "        print(\"Verification complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
